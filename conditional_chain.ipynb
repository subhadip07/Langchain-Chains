{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d58995",
   "metadata": {},
   "source": [
    "### Conditional Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6d7c22d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableBranch, RunnableLambda\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import Literal\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6dfb6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model='llama-3.1-8b-instant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "87e4dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4d9f921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedback(BaseModel):\n",
    "\n",
    "    sentiment: Literal['positive', 'negative'] = Field(description='Give the sentiment of the feedback')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "090af382",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser2 = PydanticOutputParser(pydantic_object=Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "72bf9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template='Classify the sentiment of the following feedback text. Output must be a JSON in the following format:\\n{format_instruction}\\nFeedback: {feedback}',\n",
    "    input_variables=[\"feedback\"],\n",
    "    partial_variables={\"format_instruction\": parser2.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5eeae87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chain = prompt1 | model | parser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d2e23d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template='Write an appropriate response to this positive feedback \\n {feedback}',\n",
    "    input_variables=['feedback']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c4bd69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = PromptTemplate(\n",
    "    template='Write an appropriate response to this negative feedback \\n {feedback}',\n",
    "    input_variables=['feedback']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "41734fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x:x.sentiment == 'positive', prompt2 | model | parser),\n",
    "    (lambda x:x.sentiment == 'negative', prompt3 | model | parser),\n",
    "    RunnableLambda(lambda x: \"could not find sentiment\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6b34e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = classifier_chain | branch_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5da6fce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Thank you so much for your kind words! I'm glad I could help and appreciate your feedback. It means a lot to me!\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'feedback': 'This is a beautiful phone'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3447072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+      \n",
      "    | PromptInput |      \n",
      "    +-------------+      \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | PromptTemplate |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "      +----------+       \n",
      "      | ChatGroq |       \n",
      "      +----------+       \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| PydanticOutputParser | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "       +--------+        \n",
      "       | Branch |        \n",
      "       +--------+        \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "    +--------------+     \n",
      "    | BranchOutput |     \n",
      "    +--------------+     \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3de96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-chains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
